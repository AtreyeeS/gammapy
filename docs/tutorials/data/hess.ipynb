{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# H.E.S.S. with Gammapy\n",
    "\n",
    "[H.E.S.S.](https://www.mpi-hd.mpg.de/hfm/HESS/) is an array of gamma-ray telescopes located in Namibia. Gammapy is regularly used and fully supports H.E.S.S. high level data analysis, after export to the current [open data level 3 format](https://gamma-astro-data-formats.readthedocs.io/).\n",
    "\n",
    "The H.E.S.S. data is private, and H.E.S.S. analysis is mostly documented and discussed at https://hess-confluence.desy.de/ and in H.E.S.S.-internal communication channels. However, in 2018, a small sub-set of archival H.E.S.S. data was publicly released, called the [H.E.S.S. DL3 DR1](https://www.mpi-hd.mpg.de/hfm/HESS/pages/dl3-dr1/), the data level 3, data release number 1. This dataset is 50 MB in size and is used in many Gammapy analysis tutorials, and can be downloaded via [gammapy download](https://docs.gammapy.org/dev/scripts/index.html?highlight=download).\n",
    "\n",
    "This notebook is a quick introduction to H.E.S.S. data and instrument responses and contains some specifics that are important for H.E.S.S. users:\n",
    "\n",
    "- IRF formats and shapes\n",
    "- How to handle safe energy and max offset\n",
    "- EVENTS and GTI formats (e.g. how HESS 1, 2, configs, ... are handled)\n",
    "- Link to HESS Confluence where data and help is available\n",
    "- Analysis of data reduced with H.E.S.S. internal s/w\n",
    "\n",
    "\n",
    "\n",
    "## DL3 DR1\n",
    "\n",
    "This is how to access data and IRFs from the H.E.S.S. data level 3, data release 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from astropy.coordinates import SkyCoord\n",
    "import astropy.units as u\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gammapy.data import DataStore\n",
    "from gammapy.maps import MapAxis, Map\n",
    "from gammapy.datasets import MapDatasetOnOff\n",
    "from gammapy.makers.utils import make_theta_squared_table\n",
    "from gammapy.visualization import plot_theta_squared_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_store = DataStore.from_dir(\"$GAMMAPY_DATA/hess-dl3-dr1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_store.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_store.obs_table[:2][[\"OBS_ID\", \"DATE-OBS\", \"RA_PNT\", \"DEC_PNT\", \"OBJECT\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = data_store.obs(23523)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs.events.select_offset([0, 2.5] * u.deg).peek()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs.aeff.peek()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs.edisp.peek()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs.psf.peek()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs.bkg.to_2d().plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Theta squared event distribution\n",
    "As a quick look plot it can be helpful to plot the quadratic offset (theta squared) distribution of the events. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "position = SkyCoord(ra=83.63, dec=22.01, unit=\"deg\", frame=\"icrs\")\n",
    "theta2_axis = MapAxis.from_bounds(0, 0.2, nbin=20, interp=\"lin\", unit=\"deg2\")\n",
    "\n",
    "observations = data_store.get_observations([23523, 23526])\n",
    "theta2_table = make_theta_squared_table(\n",
    "    observations=observations,\n",
    "    position=position,\n",
    "    theta_squared_axis=theta2_axis,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "nbsphinx-thumbnail": {
     "tooltip": "Explore H.E.S.S. event lists and IRFs."
    }
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 5))\n",
    "plot_theta_squared_table(theta2_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using 2D images created within internal HESS s/w\n",
    "\n",
    "It is possible to use maps created outside gammapy, eg, using internal H.E.S.S. s/w `hap`, for modelling and fitting within gammapy. For this, it is necessary to attach an appropriate energy axis with a single bin on the maps, and also ensure that the maps have proper units.\n",
    "\n",
    "In this example, we use some `hap` produced files shipped with `Gammapy-data`. Details of these files can be found in [this internal hess page](https://hess-confluence.desy.de/confluence/display/HESS/HGPS+Paper+-+Survey+Maps#HGPSPaperSurveyMaps-HAPLatestSur[â€¦]sLatestHAPmapsandwhattheycontain). \n",
    "\n",
    "Note: **we strongly recommend that you re-process the files using gammapy.makers** to avoid unnecssary errors. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read the relevant hdus\n",
    "\n",
    "counts = Map.read(\n",
    "    \"$GAMMAPY_DATA/tests/unbundled/hess/survey/hess_survey_snippet.fits.gz\",\n",
    "    hdu=\"On\",\n",
    ")\n",
    "counts_off = Map.read(\n",
    "    \"$GAMMAPY_DATA/tests/unbundled/hess/survey/hess_survey_snippet.fits.gz\",\n",
    "    hdu=\"Off\",\n",
    ")\n",
    "onExposure = Map.read(\n",
    "    \"$GAMMAPY_DATA/tests/unbundled/hess/survey/hess_survey_snippet.fits.gz\",\n",
    "    hdu=\"OnExposure\",\n",
    ")\n",
    "offExposure = Map.read(\n",
    "    \"$GAMMAPY_DATA/tests/unbundled/hess/survey/hess_survey_snippet.fits.gz\",\n",
    "    hdu=\"OffExposure\",\n",
    ")\n",
    "mask = Map.read(\n",
    "    \"$GAMMAPY_DATA/tests/unbundled/hess/survey/hess_survey_snippet.fits.gz\",\n",
    "    hdu=\"Exclusion\",\n",
    ")\n",
    "expgamma = Map.read(\n",
    "    \"$GAMMAPY_DATA/tests/unbundled/hess/survey/hess_survey_snippet.fits.gz\",\n",
    "    hdu=\"ExpGammaMap\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, attach a relevant energy axis - a reconstructed axis on irfs, and true axis on the observed quantitites. \n",
    "Ideally, the energy range should be decided by your analysis cuts, we take an approximate value here.\n",
    "We also have to attach an unit on the exposure - ensure to take it correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "energy_min = 300 * u.GeV\n",
    "energy_max = 10 * u.TeV\n",
    "energy_axis = MapAxis.from_energy_edges(\n",
    "    [energy_min, energy_max], name=\"energy\"\n",
    ")\n",
    "energy_axis_true = MapAxis.from_energy_edges(\n",
    "    [energy_min, energy_max], name=\"energy_true\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = counts.to_cube([energy_axis])\n",
    "counts_off = counts_off.to_cube([energy_axis])\n",
    "acceptance = onExposure.to_cube([energy_axis])\n",
    "acceptance_off = offExposure.to_cube([energy_axis])\n",
    "mask = mask.to_cube([energy_axis])\n",
    "\n",
    "exposure = expgamma.to_cube(\n",
    "    [energy_axis_true]\n",
    ")  # IRFs should have true energy axis\n",
    "exposure.unit = u.cm * u.cm * u.s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In this example, there is no psf present. If present, make a cube as\n",
    "# psf_map = psf.psf_kernel_map.to_cube([energy_axis_true])\n",
    "# psf = PSFKernel(psf_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataset\n",
    "dataset_onoff = MapDatasetOnOff(\n",
    "    counts=counts,\n",
    "    counts_off=counts_off,\n",
    "    exposure=exposure,\n",
    "    acceptance=acceptance,\n",
    "    acceptance_off=acceptance_off,\n",
    "    mask_fit=mask,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_onoff.exposure.plot(add_cbar=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can perform a few sanity checks to ensure that the quantities computed by `hap` and `gammapy` are exactly the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the alpha map\n",
    "alpha_hap = Map.read(\n",
    "    \"$GAMMAPY_DATA/tests/unbundled/hess/survey/hess_survey_snippet.fits.gz\",\n",
    "    hdu=\"Alpha\",\n",
    ")\n",
    "alpha_gammapy = dataset_onoff.alpha\n",
    "print(np.all(alpha_hap.data == alpha_gammapy.data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "ax1 = plt.subplot(121, projection=alpha_hap.geom.wcs)\n",
    "ax2 = plt.subplot(122, projection=alpha_gammapy.geom.wcs)\n",
    "\n",
    "alpha_hap.plot(add_cbar=True, ax=ax1)\n",
    "alpha_gammapy.plot(add_cbar=True, ax=ax2)\n",
    "ax1.set_title(\"alpha_hap\")\n",
    "ax2.set_title(\"alpha_gammapy\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can now proceed with modelling and fitting of 2D images as explain in [this notebook](../../analysis/2D/modeling_2D..ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "\n",
    "- Find the `OBS_ID` for the runs of the Crab nebula\n",
    "- Compute the expected number of background events in the whole FOV for `OBS_ID=23523` in the 1 TeV to 3 TeV energy band, from the background IRF."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next steps\n",
    "\n",
    "Now you know how to access and work with H.E.S.S. data. All other tutorials and documentation apply to H.E.S.S. and CTA or any other IACT that provides DL3 data and IRFs in the standard format."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
